{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XYu8iPeUqpH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and preprocess Fashion MNIST dataset"
      ],
      "metadata": {
        "id": "r_rX4PRQZcif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image):\n",
        "    image = (image - 127.5) / 127.5  # Normalize between [-1, 1]\n",
        "    image = tf.expand_dims(image, axis=-1)  # Add channel dimension\n",
        "    return image\n",
        "\n",
        "# Load dataset using tf.data API\n",
        "(x_train, _), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
        "dataset = dataset.map(preprocess).shuffle(60000).batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "4luB4U_HZWFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "H4NqsqEHZiP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100\n",
        "batch_size = 16\n",
        "epochs = 15\n",
        "image_size = 28"
      ],
      "metadata": {
        "id": "nPB8FBTRZWH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build the Generator and Discriminatopr\n"
      ],
      "metadata": {
        "id": "tArM_ownZqkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(256, input_dim=latent_dim))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dense(512))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dense(1024))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dense(image_size * image_size, activation='tanh'))\n",
        "    model.add(layers.Reshape((image_size, image_size, 1)))\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=(image_size, image_size, 1)))\n",
        "    model.add(layers.Dense(512))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "GAj2f5GZZWKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile the GAN"
      ],
      "metadata": {
        "id": "8g1aRB0DZ4_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gan(generator, discriminator):\n",
        "    discriminator.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),\n",
        "                          loss='binary_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "    discriminator.trainable = False\n",
        "    gan_input = layers.Input(shape=(latent_dim,))\n",
        "    generated_image = generator(gan_input)\n",
        "    validity = discriminator(generated_image)\n",
        "    gan = tf.keras.models.Model(gan_input, validity)\n",
        "    gan.compile(optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), loss='binary_crossentropy')\n",
        "    return gan\n",
        "\n"
      ],
      "metadata": {
        "id": "ABcv3s6CZWNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create models"
      ],
      "metadata": {
        "id": "XiRQJenoZ9GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "gan = build_gan(generator, discriminator)\n",
        "\n"
      ],
      "metadata": {
        "id": "7lK6w1e3ZWQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save generated images"
      ],
      "metadata": {
        "id": "3LUa_D-6aESq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images(epoch, generator, examples=25, dim=(5, 5), figsize=(5, 5)):\n",
        "    noise = np.random.normal(0, 1, (examples, latent_dim))\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = 0.5 * generated_images + 0.5  # Rescale images [0, 1]\n",
        "\n",
        "    fig, axes = plt.subplots(dim[0], dim[1], figsize=figsize)\n",
        "    count = 0\n",
        "    for i in range(dim[0]):\n",
        "        for j in range(dim[1]):\n",
        "            axes[i, j].imshow(generated_images[count, :, :, 0], cmap='gray')\n",
        "            axes[i, j].axis('off')\n",
        "            count += 1\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'fashion_mnist_epoch_{epoch}.png')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "pCSrdUBlZWSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the GAN"
      ],
      "metadata": {
        "id": "F56yjZ9caIWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(generator, discriminator, gan, epochs, batch_size):\n",
        "    half_batch = int(batch_size / 2)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for _ in range(x_train.shape[0] // batch_size):\n",
        "            # Train Discriminator\n",
        "            idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
        "            real_images = x_train[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
        "            fake_images = generator.predict(noise)\n",
        "\n",
        "            real_labels = np.ones((half_batch, 1))\n",
        "            fake_labels = np.zeros((half_batch, 1))\n",
        "\n",
        "            d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
        "            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # Train Generator\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            valid_labels = np.ones((batch_size, 1))\n",
        "\n",
        "            g_loss = gan.train_on_batch(noise, valid_labels)\n",
        "\n",
        "        # Print the progress\n",
        "        print(f\"{epoch+1}/{epochs} [D loss: {d_loss[0]}, acc: {100*d_loss[1]}%] [G loss: {g_loss}]\")\n",
        "\n",
        "        # Save generated images at intervals\n",
        "        if epoch % 10 == 0:\n",
        "            save_images(epoch, generator)\n"
      ],
      "metadata": {
        "id": "Dnxtf3FkZWVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the training"
      ],
      "metadata": {
        "id": "nwkn_2DOaPlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_gan(generator, discriminator, gan, epochs=epochs, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "-6F0KHbBZWYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate and save final synthetic images"
      ],
      "metadata": {
        "id": "6ADpbPisaSI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_images(epochs, generator)"
      ],
      "metadata": {
        "id": "ZTQlBR0RZWbP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}